{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install --file requirements.txt\n",
    "#!pip install -r requirements.txt\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#follow the link below to get your download code from from Roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(notebook=\"ultralytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"qTa6LAa4hUuW5YJMryUx\")\n",
    "project = rf.workspace(\"instituto-valenciano-de-investigaciones-agrarias-ivia\").project(\"naranjasfinal\")\n",
    "dataset = project.version(8).download(\"yolov5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /content/yolov5\n",
    "#after following the link above, recieve python code with these fields filled in\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"qTa6LAa4hUuW5YJMryUx\")\n",
    "project = rf.workspace(\"instituto-valenciano-de-investigaciones-agrarias-ivia\").project(\"naranjasfinal\")\n",
    "dataset = project.version(6).download(\"yolov5\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D:\\NaranjasFinal\\yolov5\\detect.py\n",
    "\n",
    "D:\\NaranjasFinal\\yolov5\\train.py \n",
    "\n",
    "D:\\NaranjasFinal\\yolov5\\runs\\train\\exp4\\weights\\best.pt\n",
    "\n",
    "D:\\NaranjasFinal\\yolov5\\Naranjas-3\\data.yaml\n",
    "\n",
    "D:\\NaranjasFinal\\yolov5\\Naranjas-3\\test\\images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in NaranjasFinal-40 to yolov5pytorch: 100% [212514322 / 212514322] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to NaranjasFinal-40 in yolov5pytorch:: 100%|██████████| 6719/6719 [00:03<00:00, 1981.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#MODELO DE YOLOV8 20 PARA YOLOV5\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"qTa6LAa4hUuW5YJMryUx\")\n",
    "project = rf.workspace(\"instituto-valenciano-de-investigaciones-agrarias-ivia\").project(\"naranjasfinal\")\n",
    "dataset = project.version(40).download(\"yolov5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yolo task=detect mode=train model=yolov8l.pt imgsz=640 data=\"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasYOLOv8\\NaranjasFinal-40\\data.yaml\" epochs=500 batch=8 name=yolov8n_custom patience=0\n",
    "\n",
    "#PARAMETROS YOLOV8\n",
    "#python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --batch 32 --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5s.pt\" --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-9/data.yaml\" --epochs 500 --img 512 --hyp \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\data\\hyps\\hyp.scratch-med.yaml\" --evolve --device 0\n",
    "python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\train.py\" --batch 8 --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\yolov5l.pt\" --data \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\NaranjasFinal-40\\data.yaml\" --epochs 500 --img 640 --patience 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=\"qTa6LAa4hUuW5YJMryUx\")\n",
    "project = rf.workspace(\"instituto-valenciano-de-investigaciones-agrarias-ivia\").project(\"naranjasfinal\")\n",
    "dataset = project.version(9).download(\"yolov5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=\"qTa6LAa4hUuW5YJMryUx\")\n",
    "project = rf.workspace(\"instituto-valenciano-de-investigaciones-agrarias-ivia\").project(\"naranjasfinal\")\n",
    "dataset = project.version(14).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train yolov5s on custom data for 100 epochs\n",
    "# time its performance\n",
    "#!python yolov5/train.py --img 416 --batch 16 --epochs 150 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache\n",
    "!python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\train.py\" --img 256 --batch 16 --epochs 1000 --data \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\NaranjasFinal-10\\data.yaml\" --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\yolov5s.pt\" --cache  --optimizer SDG\n",
    "\n",
    "!python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --img 1024 --batch 16 --epochs 1000 --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-14/data.yaml\" --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5s.pt\" --cache --hyp \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/data/hyps/hyp.scratch-high.yaml\" --rect --device 0 #exp7\n",
    "!python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --img 700 --batch 32 --epochs 1000 --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-3/data.yaml\" --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5s.pt\" --cache --hyp \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/data/hyps/hyp.scratch-high.yaml\" --rect --device 0\n",
    "!python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --img 500 --batch 64 --epochs 1000 --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-3/data.yaml\" --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5s.pt\" --cache #exp14\n",
    "!python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --img 1024 --batch 8 --epochs 1000 --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-14/data.yaml\" --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5s.pt\" --cache --hyp \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/data/hyps/hyp.scratch-high.yaml\" --rect --device 0 #exp20\n",
    "!python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --batch 32 --weights yolov5m6.pt --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-9/data.yaml\" --epochs 500 --img 512 --hyp \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\data\\hyps\\hyp.scratch-med.yaml\" --evolve --device 0\n",
    "python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --batch 32 --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5s.pt\" --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-9/data.yaml\" --epochs 500 --img 512 --hyp \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\data\\hyps\\hyp.scratch-med.yaml\" --evolve --device 0\n",
    "\n",
    "\n",
    "\n",
    "python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --img 640 --batch 32 --epochs 1000 --data \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\NaranjasFinal.v40i.yolov5pytorch\\data.yaml\" --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5l.pt\" --cache --hyp \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\data\\hyps\\hyp.scratch-high.yaml\" --rect --device 0 --patience 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO YOLO5 4090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --batch 64 --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5x.pt\" --data \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\NaranjasFinal.v40i.yolov5pytorch\\data.yaml\" --epochs 500 --img 640 --patience 0 --device 0 --evolve 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento actualiazando hyperparametros\n",
    "\n",
    "python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --img 1024 --batch 16 --epochs 1000 --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-14/data.yaml\" --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5l.pt\" --cache --hyp \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\data\\hyps\\hyp.scratch-med.yaml\" --device 0 #exp\n",
    "python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --img 1024 --batch 16 --epochs 1000 --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-14/data.yaml\" --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5s.pt\" --cache --hyp \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\data\\hyps\\hyp.scratch-med.yaml\" --device 0 --evolve\n",
    "python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --img 1024 --batch 16 --epochs 1000 --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-14/data.yaml\" --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5s.pt\" --cache --hyp hyperdeevolve--device 0\n",
    "\n",
    "#Probar este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intento de exp6\n",
    "!python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --img 1024 --batch 8 --epochs 1000 --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-14/data.yaml\" --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5m.pt\" --cache --device 0 --optimizer SGD #exp21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pesos de YOLOV5L.PT yolov5x.pt no hay memoria suficiente\n",
    "\n",
    "!python \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/train.py\" --img 500 --batch 64 --epochs 1000 --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-3/data.yaml\" --weights \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/yolov5x.pt\" --cache #exp4 Train\n",
    "!python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\val.py\" --batch 64 --data \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/NaranjasFinal-3/data.yaml\" --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp4\\weights\\best.pt\" --augment #exp Val\n",
    "!python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\detect.py\" --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp4\\weights\\best.pt\" --img 500 --conf 0.25 --source \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\NaranjasFinal-3\\test\\images\" --hide-labels --device 0 --save-conf --augment --visualize --line-thickness 2 #exp9 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\detect.py\" --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp20\\weights\\best.pt\" --img 416 --conf 0.25 --source \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\NaranjasFinal-14\\test\\images\" --hide-labels --device 0 --save-conf --save-crop --augment --visualize --line-thickness 2\n",
    "!python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\detect.py\" --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp20\\weights\\best.pt\" --img 1024 --conf 0.25 --source \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\101CANON\" --hide-labels --device 0 --save-conf --save-crop --augment --visualize --line-thickness 2\n",
    "\n",
    "python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\detect.py\" --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp4\\weights\\best.pt\" --img 1024 --conf 0.25 --source \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\101CANON\\flores\" --hide-labels --device 0 --save-conf --augment --visualize --line-thickness 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFERENCIA IMAGEN\n",
    "\n",
    "\n",
    "!python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\detect.py\" --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp\\weights\\best.pt\" --img 1024 --conf 0.1 --source \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\NaranjasFinal-14\\test\\images\"\n",
    "!python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\detect.py\" --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp19\\weights\\best.pt\" --img 640 --conf 0.1 --source \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\101CANON\"\n",
    "\n",
    "\n",
    "!python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\detect.py\" --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp12\\weights\\best.pt\" --img 1024 --conf 0.1 --source \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\PXL_20230321_085047211.CINEMATIC.mp4\" #exp10 Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFERENCIA VIDEO--source video.avi\n",
    "\n",
    "!python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\detect.py\"  --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp17\\weights\\best.pt\" --img 640 --conf 0.05 --source \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\101CANON\\MVI_0539.MP4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OAK \n",
    "!python main_api.py -m \"D:\\NaranjasFinal\\resultados(640)\\best_openvino_2021.4_6shave.blob\" --config \"D:\\NaranjasFinal\\resultados(640)\\best.json\" #640x640\n",
    "!python main_api.py -m \"D:\\NaranjasFinal\\resultados(416)\\best_openvino_2021.4_6shave.blob\" --config \"D:\\NaranjasFinal\\resultados(416)\\best.json\" #416x416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HEATMAPS\n",
    "\n",
    "python explain.py --source=data/images/me.png --weights=yolov5s.pt --explain-class=person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolo-heatmaps\\explain.py\" --source \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\101CANON\\IMG_0590.JPG\" --weights \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp4\\weights\\best.pt\" --explain-class=Naranja\n",
    "python explain.py --source=C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\101CANON\\IMG_0590.JPG --weights=C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp4\\weights\\best.pt --explain-class=Naranja"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRUEBA CON GRADCAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py --model-path cutom-model-path.pt --img-path img-path.jpg --output-dir outputs --names obj1,obj2,obj3 \n",
    "\n",
    "python main.py --model-path \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/runs/train/exp4/weights/best.pt\" --img-path \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/101CANON/IMG_0550.JPG\" --output-dir outputs --names Flor, Naranja, NaranjaVerde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (661670540.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 14\u001b[1;36m\u001b[0m\n\u001b[1;33m    im = \"C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\PXL_20230321_085047211.CINEMATIC.mp4\" # or file, Path, URL, PIL, OpenCV, numpy, list D:\\NaranjasFinal\\yolov5\\data\\images\\zidane.jpg\u001b[0m\n\u001b[1;37m                                                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#VISUALIZACIÓN 1 Imagen\n",
    "\n",
    "import torch\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "# Model\n",
    "#model = torch.hub.load('ultralytics/yolov5', 'custom', f\"{HOME}/runs/train/exp4/weights/best.pt\")  # yolov5n - yolov5x6 official model\n",
    "#                                            'custom', f\"{HOME}/runs/train/exp/weights/best.pt\")  # custom model C:\\Users\\Servidor\\Desktop\\AlbertoMartinez\\NaranjasFinal\\yolov5\\runs\\train\\exp4\\weights\\best.pt\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/yolov5/runs/train/exp40/weights/best.pt\")\n",
    "\n",
    "\n",
    "# ImagesD:\\NaranjasFinal\\segmV5\\yolov5\\data\\images\\IMG_9333.JPG\n",
    "#video \"D:/NaranjasFinal/101CANON/MVI_0539.MP4\"\n",
    "im = \"C:/Users/Servidor/Desktop/AlbertoMartinez/NaranjasFinal/PXL_20230321_085047211.CINEMATIC.mp4\" # or file, Path, URL, PIL, OpenCV, numpy, list D:\\NaranjasFinal\\yolov5\\data\\images\\zidane.jpg\n",
    "\n",
    "# Inference\n",
    "model.conf = 0.3\n",
    "results = model(im)\n",
    "\n",
    "# Results\n",
    "results.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n",
    "results.xyxy[0]  # im predictions (tensor)\n",
    "\n",
    "results.pandas().xyxy[0]  # im predictions (pandas)\n",
    "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
    "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
    "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie\n",
    "results.show(labels=False) #labels=False\n",
    "results.pandas().xyxy[0].value_counts('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionar clase para ver\n",
    "\n",
    "df= results.pandas().xyxy[0]\n",
    "dfnaranja = df[df['name']=='Naranja']\n",
    "dfnaranja.value_counts('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', \"D:/NaranjasFinal/yolov5/runs/train/exp4/weights/best.pt\")  # yolov5n - yolov5x6 official model\n",
    "#                                            'custom', f\"{HOME}/runs/train/exp/weights/best.pt\"  # custom model D:\\NaranjasFinal\\yolov5\\runs\\train\\exp\\weights\\best.pt\n",
    "#D:\\NaranjasFinal\\101CANON\n",
    "for img in glob.glob(\"D:/NaranjasFinal/prueba/fotos/*\") :\n",
    "# Images D:\\NaranjasFinal\\yolov5\\Naranjas-3\\test\\images\n",
    "# Inference\n",
    "    model.conf = 0.35\n",
    "    results = model(img)\n",
    "\n",
    "# Results\n",
    "    results.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n",
    "    results.xyxy[0]  # im predictions (tensor)\n",
    "    results.render()\n",
    "    results.pandas().xyxy[0]  # im predictions (pandas)\n",
    "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
    "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
    "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie\n",
    "    #results.show(labels= True)\n",
    "    #results.pandas().xyxy[0].value_counts('name')\n",
    "    df = results.pandas().xyxy[0]\n",
    "    dfnaranja = df[df['name']=='Naranja']\n",
    "    dfnaranja= dfnaranja.value_counts('name')\n",
    "    print(dfnaranja)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', \"D:/NaranjasFinal/yolov5/runs/train/exp4/weights/best.pt\")  # yolov5n - yolov5x6 official model\n",
    "#                                            'custom', f\"{HOME}/runs/train/exp/weights/best.pt\"  # custom model D:\\NaranjasFinal\\yolov5\\runs\\train\\exp\\weights\\best.pt\n",
    "#D:\\NaranjasFinal\\101CANON\n",
    "for img in glob.glob(\"D:/NaranjasFinal/Interfaz/FotosDemo/pano/Naranjas/*\") :\n",
    "# Images D:\\NaranjasFinal\\yolov5\\Naranjas-3\\test\\images\n",
    "# Inference\n",
    "    model.conf = 0.35\n",
    "    results = model(img)\n",
    "\n",
    "# Results\n",
    "    results.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n",
    "    \n",
    "    #results.xyxy  # im predictions (tensor)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Usuario/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-1-18 Python-3.10.8 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce GTX 1070 Ti, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 267 layers, 46119048 parameters, 0 gradients, 107.7 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          xmin         ymin         xmax         ymax  confidence  class  \\\n",
      "0  2722.139404   593.101440  2777.217773   650.069458    0.763284      1   \n",
      "1     0.000000   933.276550    36.423111   975.026550    0.733068      1   \n",
      "2   699.222778   772.073242   738.992493   800.335938    0.662116      1   \n",
      "3  2491.150879   762.817932  2525.262207   800.446594    0.605126      1   \n",
      "4  1701.964355  1996.638306  1739.727417  2050.291748    0.596483      2   \n",
      "5  1824.798950  1985.131348  1873.141724  2046.327881    0.413129      2   \n",
      "6  3233.439209  1837.849976  3257.114746  1859.243530    0.411401      1   \n",
      "7   808.104858  1593.374634   865.345642  1672.498047    0.399785      2   \n",
      "\n",
      "           name  \n",
      "0       Naranja  \n",
      "1       Naranja  \n",
      "2       Naranja  \n",
      "3       Naranja  \n",
      "4  NaranjaVerde  \n",
      "5  NaranjaVerde  \n",
      "6       Naranja  \n",
      "7  NaranjaVerde  \n",
      "Tamaño de la bounding box en centímetros: 5.51 x 5.70 m\n",
      "Tamaño de la bounding box en centímetros: 3.64 x 4.17 m\n",
      "Tamaño de la bounding box en centímetros: 3.98 x 2.83 m\n",
      "Tamaño de la bounding box en centímetros: 3.41 x 3.76 m\n",
      "Tamaño de la bounding box en centímetros: 3.78 x 5.37 m\n",
      "Tamaño de la bounding box en centímetros: 4.83 x 6.12 m\n",
      "Tamaño de la bounding box en centímetros: 2.37 x 2.14 m\n",
      "Tamaño de la bounding box en centímetros: 5.72 x 7.91 m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    dpi= 96\\n    inch_to_cm=2.54\\n    # Relación entre píxeles y centímetros\\n    px_to_cm = dpi / inch_to_cm\\n\\n    # Tamaño de la bounding box en centímetros\\n    width_cm = width_px / px_to_cm\\n    height_cm = height_px / px_to_cm\\n\\n    print(f\"Tamaño de la bounding box en centímetros: {width_cm:.2f} x {height_cm:.2f} cm\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VISUALIZACIÓN 1 Imagen\n",
    "\n",
    "import torch\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', \"D:/NaranjasFinal/yolov5/runs/train/exp4/weights/best.pt\")  # yolov5n - yolov5x6 official model\n",
    "#                                            'custom', f\"{HOME}/runs/train/exp/weights/best.pt\"  # custom model D:\\NaranjasFinal\\yolov5\\runs\\train\\exp\\weights\\best.pt\n",
    "\n",
    "# ImagesD:\\NaranjasFinal\\segmV5\\yolov5\\data\\images\\IMG_9333.JPG\n",
    "#video \"D:/NaranjasFinal/101CANON/MVI_0539.MP4\"\n",
    "im = \"D:/NaranjasFinal/Interfaz/FotosDemo/PXL_20230420_071455389.jpg\"# or file, Path, URL, PIL, OpenCV, numpy, list D:\\NaranjasFinal\\yolov5\\data\\images\\zidane.jpg\n",
    "\n",
    "# Inference\n",
    "model.conf = 0.3\n",
    "results = model(im)\n",
    "\n",
    "# Results\n",
    "#results.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n",
    "#results.xyxy[0]  # im predictions (tensor)\n",
    "\n",
    "#results.pandas().xyxy[0]  # im predictions (pandas)\n",
    "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
    "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
    "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie\n",
    "#results.show(labels=False) #labels=False\n",
    "#results.pandas().xyxy[0].value_counts('name')\n",
    "\n",
    "pred = results.pandas().xyxy[0]\n",
    "print(pred)\n",
    "\n",
    "for i in range(0, len(pred)):\n",
    "\n",
    "    col1 = pred.loc[i, 'xmax']\n",
    "    col2 = pred.loc[i, 'xmin']\n",
    "    col3 = pred.loc[i, 'ymax']\n",
    "    col4 = pred.loc[i, 'ymin']\n",
    "\n",
    "\n",
    "\n",
    "    width_px = (col1-col2)\n",
    "    height_px = (col3-col4)\n",
    "\n",
    "    width_m = width_px*0.1\n",
    "    height_m = height_px*0.1\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Tamaño de la bounding box en centímetros: {width_m:.2f} x {height_m:.2f} m\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    dpi= 96\n",
    "    inch_to_cm=2.54\n",
    "    # Relación entre píxeles y centímetros\n",
    "    px_to_cm = dpi / inch_to_cm\n",
    "\n",
    "    # Tamaño de la bounding box en centímetros\n",
    "    width_cm = width_px / px_to_cm\n",
    "    height_cm = height_px / px_to_cm\n",
    "\n",
    "    print(f\"Tamaño de la bounding box en centímetros: {width_cm:.2f} x {height_cm:.2f} cm\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de la bounding box en centímetros: 3.18 x 2.12 cm\n"
     ]
    }
   ],
   "source": [
    "# Tamaño de la bounding box en píxeles\n",
    "width_px = 120\n",
    "height_px = 80\n",
    "dpi= 96\n",
    "inch_to_cm=2.54\n",
    "# Relación entre píxeles y centímetros\n",
    "px_to_cm = dpi / inch_to_cm\n",
    "\n",
    "# Tamaño de la bounding box en centímetros\n",
    "width_cm = width_px / px_to_cm\n",
    "height_cm = height_px / px_to_cm\n",
    "\n",
    "print(f\"Tamaño de la bounding box en centímetros: {width_cm:.2f} x {height_cm:.2f} cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "817cdf77e807387e14f547665283ce3e8cabd7f43269f6db5bc61e6d62c6e7f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
